{
  "schema_type": "spec",
  "id": "SPEC-DAT-0002_Profile-Extraction",
  "title": "DAT Profile-Driven Extraction Flow Specification",
  "version": "1.0.0",
  "status": "accepted",
  "date": "2025-12-29",
  "author": "Mycahya Eggleston",
  "implements_adr": [
    "ADR-0011_Profile-Driven-Extraction-and-Adapters"
  ],
  "tier_0_contracts": [
    {
      "module": "shared.contracts.dat.profile",
      "classes": ["DATProfile", "TableConfig", "SelectConfig", "LevelConfig", "ContextConfig", "ContextDefaults", "OutputConfig"]
    }
  ],
  "purpose": "Define the end-to-end flow of profile-driven extraction in DAT. This spec describes how profiles are loaded, validated, and executed via the ProfileExecutor to produce flat, tabular DataFrames.",
  "scope": "subsystem:DAT",
  "related_specs": [
    "SPEC-DAT-0011_Profile-Schema: Complete YAML schema specification",
    "SPEC-DAT-0012_Extraction-Strategies: Detailed strategy implementations"
  ],
  "extraction_flow": {
    "description": "End-to-end profile extraction workflow",
    "steps": [
      {
        "id": 1,
        "name": "Profile Loading",
        "component": "ProfileLoader",
        "actions": [
          "Load YAML profile from file or database",
          "Validate against SPEC-DAT-0011 schema",
          "Compute content hash for provenance",
          "Return validated DATProfile instance"
        ]
      },
      {
        "id": 2,
        "name": "File Discovery",
        "component": "DiscoveryStage",
        "profile_usage": "datasource.filters",
        "actions": [
          "Apply file matching predicates from profile",
          "Filter files by extension, name patterns, size limits",
          "Return list of matched file paths"
        ]
      },
      {
        "id": 3,
        "name": "Context Extraction",
        "component": "ContextStage",
        "profile_usage": "context_defaults, contexts",
        "actions": [
          "Apply 4-level priority resolution: defaults → regex → content → user",
          "Extract values from filename via regex_patterns",
          "Extract values from file content via JSONPath (content_patterns)",
          "Allow user overrides for specified fields",
          "Return context dictionary"
        ]
      },
      {
        "id": 4,
        "name": "Table Selection",
        "component": "TableSelectionStage",
        "profile_usage": "levels[].tables, ui.table_selection",
        "actions": [
          "Present available tables from profile to user",
          "Apply default selections from ui.table_selection.default_selected",
          "Validate user selections against profile",
          "Return selected table IDs"
        ]
      },
      {
        "id": 5,
        "name": "Profile Execution",
        "component": "ProfileExecutor",
        "profile_usage": "FULL PROFILE",
        "actions": [
          "For each selected table, execute extraction strategy",
          "Apply strategy-specific logic (flat_object, headers_data, etc.)",
          "Inject context columns into extracted data",
          "Apply stable_columns validation",
          "Apply normalization rules",
          "Return Dict[table_id, DataFrame]"
        ]
      },
      {
        "id": 6,
        "name": "Output Generation",
        "component": "ExportStage",
        "profile_usage": "outputs, governance.limits",
        "actions": [
          "Apply output configurations (aggregations, joins)",
          "Enforce governance limits (max_rows, max_columns)",
          "Generate DataSetManifest with provenance",
          "Write Parquet files to artifact store"
        ]
      }
    ]
  },
  "profile_executor": {
    "description": "Core component that interprets profiles and executes extraction",
    "interface": {
      "execute": {
        "signature": "async def execute(profile: DATProfile, files: list[Path], context: dict) -> dict[str, pl.DataFrame]",
        "description": "Execute full profile extraction"
      },
      "extract_table": {
        "signature": "async def extract_table(table: TableConfig, data: Any, context: dict) -> pl.DataFrame",
        "description": "Extract single table using its configured strategy"
      },
      "apply_context": {
        "signature": "def apply_context(df: pl.DataFrame, context: dict, level: str) -> pl.DataFrame",
        "description": "Inject context columns into DataFrame"
      }
    },
    "strategy_dispatch": {
      "description": "ProfileExecutor dispatches to strategy implementations based on select.strategy",
      "dispatch_map": {
        "flat_object": "FlatObjectStrategy",
        "headers_data": "HeadersDataStrategy",
        "array_of_objects": "ArrayOfObjectsStrategy",
        "repeat_over": "RepeatOverStrategy (wraps base strategy)",
        "unpivot": "UnpivotStrategy",
        "join": "JoinStrategy"
      }
    }
  },
  "context_resolution": {
    "description": "4-level priority system for context value resolution",
    "priority_order": [
      {"priority": 1, "source": "user_override", "description": "Explicit user input in UI"},
      {"priority": 2, "source": "content_patterns", "description": "JSONPath from file content"},
      {"priority": 3, "source": "regex_patterns", "description": "Regex from filename/path"},
      {"priority": 4, "source": "defaults", "description": "Static defaults from profile"}
    ],
    "resolution_algorithm": "For each field, check sources in priority order; use first non-null value"
  },
  "stable_columns_enforcement": {
    "description": "Validation of extracted columns against profile expectations",
    "modes": {
      "warn": "Log warning if stable_columns missing, continue extraction",
      "error": "Raise exception if stable_columns missing, fail extraction",
      "ignore": "No validation performed"
    },
    "stable_columns_subset": {
      "true": "Allow extra columns beyond stable_columns",
      "false": "Only stable_columns allowed in output"
    }
  },
  "requirements": [
    {
      "id": "REQ-EXTRACT-001",
      "description": "All extraction MUST go through ProfileExecutor",
      "enforcement": "No hardcoded JSONPath in stage code"
    },
    {
      "id": "REQ-EXTRACT-002",
      "description": "Context resolution MUST follow 4-level priority",
      "enforcement": "ContextStage validates against profile"
    },
    {
      "id": "REQ-EXTRACT-003",
      "description": "Stable columns MUST be validated per table config",
      "enforcement": "ProfileExecutor validates after extraction"
    },
    {
      "id": "REQ-EXTRACT-004",
      "description": "Output MUST include provenance (profile_id, content_hash)",
      "enforcement": "DataSetManifest includes profile_id field"
    }
  ],
  "adapter_integration": {
    "description": "How ProfileExecutor integrates with format adapters",
    "flow": [
      "ProfileExecutor receives raw file content from adapter",
      "For JSON: adapter parses to dict, ProfileExecutor applies JSONPath",
      "For CSV/Excel: adapter produces DataFrame, ProfileExecutor applies column mappings",
      "ProfileExecutor is format-agnostic; adapters handle I/O"
    ]
  },
  "references": [
    "ADR-0011_Profile-Driven-Extraction-and-Adapters: Architecture decisions",
    "SPEC-DAT-0011_Profile-Schema: YAML profile schema",
    "SPEC-DAT-0012_Extraction-Strategies: Strategy implementations",
    "SPEC-DAT-0003_Adapter-Interface-Registry: Adapter contracts",
    "shared/contracts/dat/profile.py: Tier-0 contracts"
  ]
}
