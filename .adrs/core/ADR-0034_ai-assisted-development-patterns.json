{
  "schema_type": "adr",
  "id": "ADR-0034_ai-assisted-development-patterns",
  "title": "AI-Assisted Development Patterns for Solo-Dev Optimization",
  "status": "accepted",
  "date": "2025-12-28",
  "review_date": "2026-06-28",
  "deciders": "Mycahya Eggleston",
  "scope": "core",
  "provenance": [
    {
      "at": "2025-12-28",
      "by": "Mycahya Eggleston",
      "note": "Initial draft to establish AI-parseable code patterns for solo-dev workflow"
    }
  ],
  "context": "As a solo developer relying heavily on AI coding assistants (Windsurf Cascade, Claude, etc.) for implementation, bug fixing, documentation, and planning, the codebase must be optimized for AI comprehension. AI assistants perform best when code follows predictable patterns, uses consistent naming conventions, and provides clear structural signals. Without explicit AI-optimization patterns, AI assistants may generate inconsistent code, misunderstand project conventions, or require excessive context to be effective. This ADR establishes mandatory patterns that make the codebase AI-native: predictable file locations, consistent naming, comprehensive docstrings, and explicit structural organization.",
  "decision_primary": "All code patterns MUST be AI-parseable and predictable. This includes: (1) File naming using {domain}_{action}.py pattern, (2) Function naming using {verb}_{noun} pattern, (3) Google-style docstrings with Args, Returns, Raises, Example sections, (4) Comments explaining 'why' not 'what', (5) Flat directory structure within modules (max 2 levels deep), (6) Absolute imports only, grouped by origin (stdlib → third-party → local). These patterns enable AI assistants to reliably generate, modify, and understand code without extensive context-gathering.",
  "decision_details": {
    "approach": "Codify patterns that optimize for AI assistant comprehension while maintaining human readability",
    "constraints": [
      "All Python files MUST follow {domain}_{action}.py naming (e.g., dataset_loader.py, stage_orchestrator.py)",
      "All functions MUST follow {verb}_{noun} naming (e.g., load_dataset, render_chart, validate_manifest)",
      "All public functions MUST have Google-style docstrings with Args, Returns, Raises sections",
      "All docstrings MUST include Example section for non-trivial functions",
      "Comments MUST explain 'why' (rationale), never 'what' (AI can read code)",
      "Directory structure MUST be flat within modules; max 2 levels: apps/{tool}/backend/src/{module}/",
      "All imports MUST be absolute (no relative imports)",
      "Import groups MUST be ordered: stdlib → third-party → local (with blank line separators)",
      "Class names MUST use PascalCase with descriptive suffixes (e.g., DataSetLoader, StageOrchestrator)",
      "Constants MUST use SCREAMING_SNAKE_CASE at module level"
    ],
    "file_naming": {
      "pattern": "{domain}_{action}.py",
      "examples": {
        "correct": [
          "dataset_loader.py",
          "stage_orchestrator.py",
          "artifact_store.py",
          "manifest_validator.py",
          "chart_renderer.py"
        ],
        "incorrect": [
          "DataSetLoader.py",
          "loader.py",
          "utils.py",
          "helpers.py",
          "misc.py"
        ]
      },
      "rationale": "AI can infer file purpose from name without reading contents. Generic names like 'utils.py' force AI to read entire file to understand scope."
    },
    "function_naming": {
      "pattern": "{verb}_{noun}",
      "verbs": {
        "data_access": [
          "load",
          "save",
          "fetch",
          "store",
          "read",
          "write"
        ],
        "transformation": [
          "parse",
          "render",
          "convert",
          "transform",
          "format"
        ],
        "validation": [
          "validate",
          "check",
          "verify",
          "ensure",
          "assert"
        ],
        "lifecycle": [
          "create",
          "delete",
          "update",
          "initialize",
          "dispose"
        ],
        "computation": [
          "calculate",
          "compute",
          "derive",
          "aggregate",
          "summarize"
        ],
        "queries": [
          "get",
          "find",
          "list",
          "search",
          "filter"
        ]
      },
      "examples": {
        "correct": [
          "load_dataset()",
          "render_chart()",
          "validate_manifest()",
          "create_artifact()",
          "calculate_variance()"
        ],
        "incorrect": [
          "dataset()",
          "do_chart()",
          "process()",
          "handle()",
          "run()"
        ]
      },
      "rationale": "Verb-noun pattern enables AI to understand function purpose without reading implementation. Generic verbs like 'process' or 'handle' are ambiguous."
    },
    "docstring_format": {
      "style": "Google-style",
      "required_sections": [
        "Summary (one-liner)",
        "Args",
        "Returns",
        "Raises"
      ],
      "optional_sections": [
        "Example",
        "Note",
        "Warning",
        "See Also"
      ],
      "template": "\"\"\"One-line summary of function purpose.\n\nOptional extended description if needed.\n\nArgs:\n    param_name: Description of parameter.\n    another_param: Description with type if not obvious.\n\nReturns:\n    Description of return value.\n\nRaises:\n    ExceptionType: When this exception is raised.\n\nExample:\n    >>> result = function_name(arg1, arg2)\n    >>> print(result)\n    expected_output\n\"\"\"",
      "rationale": "Google-style is widely recognized by AI assistants. Structured sections enable AI to extract specific information (e.g., 'what exceptions can this raise?')."
    },
    "comment_philosophy": {
      "rule": "Comments explain WHY, never WHAT",
      "correct_examples": [
        "# SHA-256 chosen for collision resistance and determinism per ADR-0007",
        "# Preserve artifacts on unlock to prevent data loss per ADR-0002",
        "# Windows requires spawn-safe concurrency; fork() unavailable"
      ],
      "incorrect_examples": [
        "# Load the dataset",
        "# Iterate over items",
        "# Return the result"
      ],
      "rationale": "AI can read code to understand WHAT it does. Humans (and AI) need WHY comments to understand rationale. WHAT comments are noise."
    },
    "directory_structure": {
      "rule": "Flat within modules, max 2 levels deep",
      "correct_structure": [
        "apps/data_aggregator/backend/src/dat/",
        "  stage_orchestrator.py",
        "  artifact_store.py",
        "  manifest_validator.py",
        "  adapters/",
        "    csv_adapter.py",
        "    parquet_adapter.py"
      ],
      "incorrect_structure": [
        "apps/data_aggregator/backend/src/dat/",
        "  core/",
        "    orchestration/",
        "      stages/",
        "        implementations/",
        "          stage_orchestrator.py"
      ],
      "rationale": "Deep nesting forces AI to navigate multiple levels to find files. Flat structure enables AI to locate files by name alone."
    },
    "import_organization": {
      "rule": "Absolute imports only, grouped by origin",
      "order": [
        "1. Standard library imports",
        "2. Third-party imports",
        "3. Local application imports"
      ],
      "separator": "Blank line between groups",
      "example": "from collections.abc import Mapping\nfrom pathlib import Path\n\nimport polars as pl\nfrom pydantic import BaseModel\n\nfrom shared.contracts.core.dataset import DataSetManifest\nfrom shared.storage.artifact_store import ArtifactStore",
      "rationale": "Absolute imports are unambiguous. Grouping enables AI to quickly identify dependencies. Relative imports require AI to track current file location."
    },
    "implementation_specs": []
  },
  "consequences": [
    "✅ POSITIVE: AI assistants generate consistent code matching project patterns",
    "✅ POSITIVE: AI can locate files by inferring path from name (dataset_loader.py in dat/)",
    "✅ POSITIVE: AI can understand function purpose from name alone (load_dataset = data access)",
    "✅ POSITIVE: Docstrings provide AI with structured metadata for code generation",
    "✅ POSITIVE: WHY comments give AI rationale context for decision-making",
    "✅ POSITIVE: Flat structure reduces AI navigation overhead",
    "✅ POSITIVE: Human readability maintained (patterns are also human-friendly)",
    "❌ NEGATIVE: More verbose file/function names (mitigated: clarity > brevity)",
    "❌ NEGATIVE: Docstring requirement adds upfront effort (mitigated: AI can generate docstrings)",
    "❌ NEGATIVE: Flat structure may group unrelated files (mitigated: max 2 levels allows logical grouping)",
    "⚠️ NEUTRAL: Requires discipline to maintain patterns (CI enforcement planned)"
  ],
  "alternatives_considered": [
    {
      "name": "No AI-Specific Patterns (Standard Python)",
      "pros": "Less opinionated, flexible naming, no special rules",
      "cons": "AI generates inconsistent code, requires more context-gathering, higher error rate",
      "rejected_reason": "Solo-dev relies on AI; optimizing for AI is ROI-positive"
    },
    {
      "name": "Framework-Specific Patterns (Django/FastAPI conventions)",
      "pros": "Well-documented, AI trained on these patterns, community familiarity",
      "cons": "May not fit project domain, constrains design choices, framework lock-in",
      "rejected_reason": "Project-specific patterns better fit domain; can adopt framework conventions selectively"
    },
    {
      "name": "Hungarian Notation (type prefixes)",
      "pros": "Type information in names, unambiguous",
      "cons": "Redundant with type hints, verbose, outdated practice",
      "rejected_reason": "Python type hints make Hungarian notation redundant; Pydantic provides runtime validation"
    }
  ],
  "tradeoffs": "We trade naming brevity for AI comprehension. Longer, descriptive names (load_dataset vs get) add characters but dramatically improve AI's ability to understand and generate correct code. The flat directory structure trades organizational depth for navigation simplicity.",
  "rollout_plan": [
    "1. Document patterns in AI_CODING_GUIDE.md (reference this ADR)",
    "2. Add ruff rules for import organization (isort)",
    "3. Add custom linter for file/function naming (future)",
    "4. Audit existing files for pattern compliance",
    "5. Refactor non-compliant files incrementally",
    "6. Update global_rules.md memory with pattern summary"
  ],
  "rollback_plan": "If patterns prove too restrictive: (1) Relax specific constraints (e.g., allow 3-level nesting), (2) Remove custom linter rules, (3) Keep Google docstrings (universally beneficial). Rollback is low-risk since patterns are conventions, not breaking changes.",
  "metrics_to_watch": [
    "AI assistant code generation accuracy (subjective assessment)",
    "Time to implement features with AI assistance (should decrease)",
    "Number of AI-generated errors requiring manual correction (should decrease)",
    "Developer satisfaction with codebase navigability (self-assessment)"
  ],
  "guardrails": [
    {
      "id": "ai-file-naming-pattern",
      "rule": "All Python files MUST follow {domain}_{action}.py naming pattern",
      "enforcement": "Code review; future custom linter",
      "scope": "core"
    },
    {
      "id": "ai-function-naming-pattern",
      "rule": "All functions MUST follow {verb}_{noun} naming pattern",
      "enforcement": "Code review; future custom linter",
      "scope": "core"
    },
    {
      "id": "ai-docstring-required",
      "rule": "All public functions MUST have Google-style docstrings with Args, Returns, Raises",
      "enforcement": "ruff D100-D107 rules; CI fails on missing docstrings",
      "scope": "core"
    },
    {
      "id": "ai-comments-why-not-what",
      "rule": "Comments MUST explain WHY (rationale), never WHAT (code description)",
      "enforcement": "Code review (manual)",
      "scope": "core"
    },
    {
      "id": "ai-absolute-imports",
      "rule": "All imports MUST be absolute; no relative imports",
      "enforcement": "ruff I001/I002 rules; CI fails on relative imports",
      "scope": "core"
    },
    {
      "id": "ai-directory-depth",
      "rule": "Directory structure MUST be max 2 levels deep within modules",
      "enforcement": "Code review; directory structure documentation",
      "scope": "core"
    }
  ],
  "cross_cutting_guardrails": [
    "ADR-0045#contracts-defined-pydantic-shared-contracts: Contracts follow same naming patterns",
    "ADR-0045: Docstrings feed into auto-generated documentation"
  ],
  "references": [
    "Google Python Style Guide: https://google.github.io/styleguide/pyguide.html",
    "PEP 257 - Docstring Conventions: https://peps.python.org/pep-0257/",
    "PEP 8 - Style Guide for Python Code: https://peps.python.org/pep-0008/",
    "docs/AI_CODING_GUIDE.md: Project-specific AI coding guide"
  ],
  "tags": [
    "ai-assisted",
    "naming-conventions",
    "docstrings",
    "code-organization",
    "solo-dev",
    "developer-experience"
  ],
  "affected_components": [
    "All Python source files",
    "docs/AI_CODING_GUIDE.md",
    "pyproject.toml (ruff configuration)",
    ".pre-commit-config.yaml"
  ]
}